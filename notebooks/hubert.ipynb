{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lBWdlkC4978",
    "outputId": "ac6676ca-9b0f-4a87-9d42-2d48b3bda936"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstallation complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "!apt-get -qq update\n",
    "!apt-get -qq install -y ffmpeg\n",
    "!pip -q install transformers torch datasets evaluate jiwer librosa soundfile\n",
    "print(\"Installation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 2: Imports & Configuration\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import subprocess\n",
    "import evaluate\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import HubertForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Configuration\n",
    "MODEL_ID = \"facebook/hubert-large-ls960-ft\" # English Pre-trained Model\n",
    "DATASET_ID = \"sukumbasar/ASR_EchoBase_Raw\"\n",
    "TARGET_SAMPLING_RATE = 16000\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device set to: {device}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiMl7Xqo54IP",
    "outputId": "afe6c3ce-643c-45c0-92f8-36d8ed833ab6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device set to: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 3: Utility Functions\n",
    "\n",
    "def convert_bytes_to_array(bytes_data):\n",
    "    \"\"\"\n",
    "    Converts raw m4a audio bytes to a 16kHz numpy array using ffmpeg.\n",
    "    \"\"\"\n",
    "    # Create temp input file\n",
    "    fin = tempfile.NamedTemporaryFile(suffix=\".m4a\", delete=False)\n",
    "    fin.write(bytes_data)\n",
    "    fin.flush()\n",
    "    fin.close()\n",
    "\n",
    "    # Create temp output file\n",
    "    fout = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    out_path = fout.name\n",
    "    fout.close()\n",
    "\n",
    "    # Convert using ffmpeg\n",
    "    try:\n",
    "        subprocess.run([\"ffmpeg\", \"-y\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "                        \"-i\", fin.name, \"-ac\", \"1\", \"-ar\", str(TARGET_SAMPLING_RATE), out_path],\n",
    "                       check=True)\n",
    "        speech_array, _ = librosa.load(out_path, sr=TARGET_SAMPLING_RATE)\n",
    "    finally:\n",
    "        if os.path.exists(fin.name): os.remove(fin.name)\n",
    "        if os.path.exists(out_path): os.remove(out_path)\n",
    "\n",
    "    return speech_array\n",
    "\n",
    "def normalize_text_strict(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes text: lowercase, remove punctuation, keep Turkish chars.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = text.lower()\n",
    "    # Keep standard letters, numbers and Turkish characters\n",
    "    text = re.sub(r\"[^a-z\u00e7\u011f\u0131\u00f6\u015f\u00fc0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ],
   "metadata": {
    "id": "RK-JAM9Z6C47"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 4: Load Dataset\n",
    "print(f\"Loading dataset from Hugging Face: {DATASET_ID}...\")\n",
    "ds = load_dataset(DATASET_ID, split=\"train\")\n",
    "\n",
    "# Keep audio as bytes to handle m4a format manually\n",
    "ds = ds.cast_column(\"audio\", Audio(decode=False))\n",
    "\n",
    "print(f\"Dataset loaded. Total samples: {len(ds)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276,
     "referenced_widgets": [
      "2e18815d75664f9594504b9f66913520",
      "7fdbcdbb6f0c46fd80b5ce46430f6776",
      "cf5435a5b82b4a5c89d0704986ae5702",
      "20c2a17749c04231a746b759d7ea9df1",
      "0faac5a127a649f2b9392f4608bc8fac",
      "69d891a12c6e4f1ba5fc56235039e3fa",
      "7fef96b089ed4bcbb733d1b087a5e823",
      "84237a529a394c9196a4642bedfd512d",
      "4af70b26fb604364b072e1955524f481",
      "c7ac17a6e2834608a4749cc581c3bd6a",
      "5e93add9520e441c80d310245ecc64a2",
      "3bc37d7c845a47e2a01de09ec541d0bb",
      "d1a0f44da9994b2da4d0df623ad939b1",
      "81f6f663723b472f9ded19eca17c714d",
      "da716c9d56494e19987b20a12cddfa4e",
      "65d1a5cf98b244f49d09fc3a435e96e3",
      "1f38c579396442c99fb7e0a7647d2c82",
      "28f28cf809444ad2930062ddc923bfcc",
      "b7bb34b5e8234f30aa49f71a317fed04",
      "2c7cb38eb4164756b38d717159f9c285",
      "1560abd0c80b415b8e2182a84a8f6646",
      "05b0cee703d54c4e80a48534a0b13cd6",
      "1ccba15594374ec7a2ab94b899ef8261",
      "4839e4d6d6cf4aaaaa2d308c6a5d3784",
      "fe00495724d242378d3878131098a492",
      "8c0a4b3f1e5a4459b23992de48f8c095",
      "9f39a3a5a84349f8951fea5bf3dfd94c",
      "4ba682cbd45545f387a9d1927871dacb",
      "563e454fe2524138939a981c913ca92e",
      "daffe2b862814c67bb40be85a43f7c6b",
      "74a21ab6ca0448bfaeba64b711907c9d",
      "73649331f9ec4a1496437b10bbaab997",
      "de1876d220a34a29bf1e9f525310fb34"
     ]
    },
    "id": "JF35rDgW6FoG",
    "outputId": "f0dd2c38-6fa9-4248-8288-a10666594fb7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading dataset from Hugging Face: sukumbasar/ASR_EchoBase_Raw...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e18815d75664f9594504b9f66913520"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/10.7M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bc37d7c845a47e2a01de09ec541d0bb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ccba15594374ec7a2ab94b899ef8261"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset loaded. Total samples: 50\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 5: Load Model and Processor\n",
    "print(f\"Loading model: {MODEL_ID}...\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = HubertForCTC.from_pretrained(MODEL_ID)\n",
    "\n",
    "model.to(device)\n",
    "print(\"Model loaded successfully on GPU.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245,
     "referenced_widgets": [
      "d61c6837684f4d15881c51c1aae351a3",
      "c4cf2f4fa14b47e496b1bc0a83180088",
      "cee9641071704c71912048aca7e665ac",
      "71cbb3fec0424c41af9c01f65fcd8fc9",
      "91719c6597f9432e80743dfea319d9ce",
      "f08934af0a09436c8ee748199aa1e525",
      "997b09c9e4054880bb8b7eb363634f07",
      "b31f6a87ff1d4e7686b247b685aaa1eb",
      "66851b61f4cf41ad9a2a6aefd485cce2",
      "2bdbda589a1848429e26e9780ccee51e",
      "c68790aab16d4f65a1279c101574339d",
      "c6637b898ef146359d412ceeb3e32ab4",
      "86cc6594b4fd4f8e9e3d6b16b785c2e0",
      "d886fdb5e723429d8481c6ebc7c51e1b",
      "c4b93565231144fd8b54f04b4faa2cae",
      "50cb0db6b5d94c2ea3f077325b96f574",
      "16b97a51d70146e2a819894e1ed1bf24",
      "604f4ce3418845fba7df6ba678914e8c",
      "c4a6795c1ffa4227a46a6e91a1bf529d",
      "1c1a8dd32b4542c38e3d7744278aedaa",
      "e0e14d9046844cecb00680dfcb9423c1",
      "2a6bf76bccd94ce6914c436224f643b3",
      "8d96514908e742528f7c9f60209b0e22",
      "9963df38b4944551aced5937b5f4bca6",
      "a29e70c55676462dba0c34aa66926c4a",
      "e8c14e5d70544798a36edf9916215df7",
      "e5ab502ad8a646a8b003277c9afe658a",
      "a7705532971f4930b5a425195cbf4edc",
      "5acbd5d50c5344638b7ca644b26033b6",
      "3ae7ceab729b49c1b0dc674ef4f448b1",
      "f6d53afce14d4116a0c0f37c55af6400",
      "a3db51aa4d0548a996176f545ffb71ff",
      "1d9314e275a84606ab506c4a20870ffd",
      "179bbeb6d2de4566be08cb2c3acb176b",
      "0758418f55934cb99bd2ad374c22b6c3",
      "e3c20750a52b4d49b3292a0fb560df7a",
      "75934ec425eb4f8ba2130b6ec9620159",
      "7b67dc0fd84947ce83ae22d6f2a952dc",
      "156312bf6857417eb7ee1ac20a5a5c4f",
      "ec893aec2f2744cd97a8f3f453bda889",
      "88f25594af934b42b9bce6ce398a9686",
      "ee93cc9a01bc4b5e93b66abe9a833623",
      "19d51b805cb84c2e83de85b5c94e7aea",
      "fd99abeae8d94fd284ade3166539705d",
      "958e0972541945428980809aa6770e3e",
      "815c3336f7d843eba45871552ae3adda",
      "1498c39604574dce96b2414f530c7f8a",
      "401a30d79d1148469a98894ca542a1ff",
      "b65d06fb8fa74d919b200aedd9f53ec2",
      "eed8a91442cf472a87fad90737970afe",
      "dea2f683cdcc45b097997c98eac7359d",
      "c1dfa025b7d04362bbec0615d8fb2764",
      "219c0f6e020e4643a55110c20a0c270b",
      "c6c6b432c1b547f182d5cdb722515b5a",
      "5b70804fee0e4f20a8df0f8cf8a8b44b",
      "393d664f290542f7b7efd7da45f7f515",
      "da07a0613fa34f6b91d2c7d7ea228661",
      "0fe5ef79df4148bd9c2f2889869e8e81",
      "53d32d65d62e4fe8b568ca24aa136ad2",
      "345ab29cdbea4578878937bacc8bb500",
      "c75ee124f42a4712980502026f157c95",
      "e62f244250374c13860c85d0408ea518",
      "0cb0906b8aaf457a9ee2c4bcc23df3d9",
      "281d1d5d84804c478fef1fe7f9950745",
      "9f7a38cae28c4d57a77082e24977f0e6",
      "f6f870382a5b4b008d33324e14719c98"
     ]
    },
    "id": "9ksJ_v3P6KHL",
    "outputId": "3f99041e-0c96-4ec9-9c05-2d9d2246bf53"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading model: facebook/hubert-large-ls960-ft...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d61c6837684f4d15881c51c1aae351a3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6637b898ef146359d412ceeb3e32ab4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d96514908e742528f7c9f60209b0e22"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "179bbeb6d2de4566be08cb2c3acb176b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "958e0972541945428980809aa6770e3e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "393d664f290542f7b7efd7da45f7f515"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model loaded successfully on GPU.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 6: Run Inference Loop\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "print(\"Starting inference process...\")\n",
    "\n",
    "for i, example in enumerate(ds):\n",
    "    try:\n",
    "        audio_bytes = example[\"audio\"][\"bytes\"]\n",
    "        ref_text = example[\"text\"]\n",
    "\n",
    "        # 1. Preprocess Audio\n",
    "        speech_input = convert_bytes_to_array(audio_bytes)\n",
    "\n",
    "        # 2. Model Input Preparation\n",
    "        inputs = processor(speech_input, sampling_rate=TARGET_SAMPLING_RATE, return_tensors=\"pt\", padding=True)\n",
    "        input_values = inputs.input_values.to(device)\n",
    "\n",
    "        # 3. Prediction (No Gradients)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_values).logits\n",
    "\n",
    "        # 4. Decode\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "        # 5. Normalize\n",
    "        norm_pred = normalize_text_strict(transcription)\n",
    "        norm_ref = normalize_text_strict(ref_text)\n",
    "\n",
    "        predictions.append(norm_pred)\n",
    "        references.append(norm_ref)\n",
    "\n",
    "        # Progress Log\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(ds)} samples...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {i}: {e}\")\n",
    "\n",
    "print(\"Inference finished.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206,
     "referenced_widgets": [
      "d65b5a45fa7f47c2845477baf6512427",
      "5c535725441a41e2b1afeba82a4882a9",
      "c59cabeeff9a4309a33a633dd4271b7b",
      "7701fa35be8b4bc99a8220fd87962af6",
      "5a87f3f5a5744c9db56d974c437c68bc",
      "39119005313b4b79a7c09882320577f1",
      "a31ca59c90de40d9a403d8b5275f1fd3",
      "f7d0bb6abb7744de91cd1d9b5d67b7fb",
      "0b62ac2d432344cc931a2f8a2f4a88e1",
      "f669bd4bba874f7082118cac11642cd8",
      "6479e3914bed42fa8096d3dd9d7aa304",
      "a11f0851664341b29675da0cf9959317",
      "c7e0b64e064645d8ab6b6f4211ef7297",
      "565fc3025e8d4f59adffa6fab92c6878",
      "b64dad6f48534e7e817e64cc4ee30a8d",
      "ec0d8c48dcfe4b91a5b564f3ec23e34e",
      "f6409a8f015840b08c2102f71425460f",
      "d1e017e2e27a429a831c76b582c17184",
      "01080a195be64a71afec3b8704f8840a",
      "dad8cba27e5649c8b6a32f639f638ddc",
      "ba92f68dbafd41b9a3fc380d6855843e",
      "fc6a0fd1eb4d4c83a3ba9bca013f985c"
     ]
    },
    "id": "zzT7SUf66Rr7",
    "outputId": "d650cd62-1a5b-44a8-ccc3-2de7b6c5616a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d65b5a45fa7f47c2845477baf6512427"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a11f0851664341b29675da0cf9959317"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting inference process...\n",
      "Processed 10/50 samples...\n",
      "Processed 20/50 samples...\n",
      "Processed 30/50 samples...\n",
      "Processed 40/50 samples...\n",
      "Processed 50/50 samples...\n",
      "Inference finished.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 7: Calculate and Display Metrics\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"=== EVALUATION RESULTS ({MODEL_ID}) ===\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "final_wer = wer_metric.compute(predictions=predictions, references=references)\n",
    "final_cer = cer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(f\"Overall WER: {final_wer:.4f}\")\n",
    "print(f\"Overall CER: {final_cer:.4f}\")\n",
    "\n",
    "print(\"\\n--- Sample Predictions vs References ---\")\n",
    "for i in range(min(5, len(predictions))):\n",
    "    print(f\"Ref : {references[i]}\")\n",
    "    print(f\"Pred: {predictions[i]}\")\n",
    "    print(\"-\" * 20)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hI0jz6Vi6i9R",
    "outputId": "4da08df4-2fc8-44c2-8eb4-295f7d2fe71b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "========================================\n",
      "=== EVALUATION RESULTS (facebook/hubert-large-ls960-ft) ===\n",
      "========================================\n",
      "Overall WER: 1.0635\n",
      "Overall CER: 0.4904\n",
      "\n",
      "--- Sample Predictions vs References ---\n",
      "Ref : bug\u00fcn hava olduk\u00e7a sakin\n",
      "Pred: bogunhava oldukcasykin\n",
      "--------------------\n",
      "Ref : toplant\u0131 saatini \u00fc\u00e7 bu\u00e7u\u011fa erteledim\n",
      "Pred: top land to sigtin it wihwould try it a little\n",
      "--------------------\n",
      "Ref : yo\u011fun trafik nedeniyle otob\u00fcs yar\u0131m saatten fazla gecikti\n",
      "Pred: yon treficnedenile otobserum satan fata gijicte\n",
      "--------------------\n",
      "Ref : bu dosyay\u0131 ne zaman teslim etmemiz gerekiyor\n",
      "Pred: budosn as amantis smatmos getacure\n",
      "--------------------\n",
      "Ref : e posta adresimi yanl\u0131\u015f yazm\u0131\u015f olabilirim tekrar kontrol eder misin\n",
      "Pred: e porsa dismiant chasen cholleblir tecra contrele darms\n",
      "--------------------\n"
     ]
    }
   ]
  }
 ]
}